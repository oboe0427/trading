# src/models/har_rv.py
"""
HAR / log-HAR for USDJPY 5min

í”„ë¡œì íŠ¸ êµ¬ì¡°:
trading-project/
    data/
        usdjpym5_indicators_0529-1204.csv
    src/
        models/
            har_rv.py

ì„¤ì • ì˜ˆ:
- H = 1,3,6,12 (ë‹¤ìŒ Hê°œ 5ë¶„ RV â†’ 5,15,30,60ë¶„)
- S = 12 (1ì‹œê°„)
- M = 48 (4ì‹œê°„)
- L = 288 (24ì‹œê°„)

CSV ì „ì œ:
- ';' êµ¬ë¶„ì
- ì»¬ëŸ¼: Date, Time, Open, High, Low, Close, ...
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Tuple, Dict, Iterable
from pathlib import Path

import numpy as np
import pandas as pd
import statsmodels.api as sm


# ---------------------------------------------------------------------
# ì„¤ì •ê°’ ê°ì²´
# ---------------------------------------------------------------------
@dataclass
class HARConfig:
    """HAR-RV ìœˆë„ìš° ì„¤ì • ë° ê¸°ë³¸ ì˜µì…˜"""
    H: int = 1          # ì˜ˆì¸¡ horizon (ë‹¤ìŒ Hê°œ 5ë¶„ RV)
    S: int = 12         # short window (1ì‹œê°„ = 12 * 5ë¶„ë´‰)
    M: int = 48         # medium window (4ì‹œê°„ = 48 * 5ë¶„ë´‰)
    L: int = 288        # long window (24ì‹œê°„ = 288 * 5ë¶„ë´‰)
    price_col: str = "Close"


# ---------------------------------------------------------------------
# ë°ì´í„° ë¡œë”©
# ---------------------------------------------------------------------
def load_usdjpy_indicators(
    csv_path: str | Path,
    src_utc_offset: int = 2,   # ì›ë³¸ CSV ì‹œê°„ëŒ€ (UTC+2)
    dst_utc_offset: int = 9,   # ë³€í™˜í•˜ê³  ì‹¶ì€ ì‹œê°„ëŒ€ (UTC+9, í•œêµ­)
) -> pd.DataFrame:
    """
    usdjpym5_indicators_0529-1204.csv ì „ìš© ë¡œë”

    - ';' êµ¬ë¶„ì
    - Date, Time -> timestamp ì¸ë±ìŠ¤
    - CSVëŠ” UTC+2 ê¸°ì¤€ìœ¼ë¡œ ê¸°ë¡ë˜ì–´ ìˆê³ ,
      ë°˜í™˜ë˜ëŠ” timestamp / Date / Time ì€ UTC+9 ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜ëœë‹¤.
    """
    csv_path = Path(csv_path)
    df = pd.read_csv(csv_path, sep=";")

    # 1) CSVì˜ Date+Timeì„ naive datetimeìœ¼ë¡œ íŒŒì‹± (ì›ë³¸: UTC+2)
    ts = pd.to_datetime(df["Date"] + " " + df["Time"])

    # 2) UTC+2 -> UTC+9 ë¡œ ì‹œí”„íŠ¸ (ê¸°ë³¸: +7ì‹œê°„)
    diff_hours = dst_utc_offset - src_utc_offset
    ts_local = ts + pd.to_timedelta(diff_hours, unit="h")

    # 3) ë³€í™˜ëœ timestampë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
    df["timestamp"] = ts_local
    df = df.sort_values("timestamp").set_index("timestamp")

    # ğŸ”¹ 4) Date / Time ì»¬ëŸ¼ë„ UTC+9 ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±
    # (í•„ìš”í•˜ë©´ í¬ë§·ì€ ì—¬ê¸°ì„œ ë°”ê¾¸ë©´ ë¨)
    df["Date"] = df.index.strftime("%Y.%m.%d")   # ì˜ˆ: 2025.12.09
    df["Time"] = df.index.strftime("%H:%M")      # ì˜ˆ: 13:25  (5ë¶„ë´‰ì´ë¼ ë³´í†µ ë¶„ ë‹¨ìœ„ë©´ ì¶©ë¶„)

    return df


# ---------------------------------------------------------------------
# RV / log-RV ê¸°ë³¸ ì²˜ë¦¬
# ---------------------------------------------------------------------
def compute_rv(df: pd.DataFrame, price_col: str = "Close") -> pd.DataFrame:
    """
    5ë¶„ realized variance (RV) ê³„ì‚°.

    rv_t = (log(C_t) - log(C_{t-1}))^2

    Returns:
        'log_price', 'log_ret', 'rv' ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë³µì‚¬ë³¸
    """
    df = df.copy()
    df["log_price"] = np.log(df[price_col].astype(float))
    df["log_ret"] = df["log_price"].diff()
    df["rv"] = df["log_ret"] ** 2
    return df


def prepare_base_rv_df(
    df: pd.DataFrame,
    price_col: str = "Close",
    eps: float = 1e-12,
) -> pd.DataFrame:
    """
    RV, log-RV ëª¨ë‘ ê°€ì§€ëŠ” ë² ì´ìŠ¤ df ìƒì„±.

    - rv ì—†ìœ¼ë©´ compute_rvë¡œ ê³„ì‚°
    - log_rv ì—†ìœ¼ë©´ log(rv + eps) ê³„ì‚°
    """
    if "rv" not in df.columns:
        df = compute_rv(df, price_col=price_col)
    else:
        df = df.copy()

    if "log_rv" not in df.columns:
        df["log_rv"] = np.log(df["rv"] + eps)

    return df


# ---------------------------------------------------------------------
# (1) Level HAR-RV (ê·¸ëƒ¥ rv ê¸°ì¤€)
# ---------------------------------------------------------------------
def add_har_features(df: pd.DataFrame, cfg: HARConfig) -> pd.DataFrame:
    """
    HAR-RVìš© S/M/L ìœˆë„ìš° í”¼ì²˜ + ë¯¸ë˜ RV(H-step) íƒ€ê²Ÿ ìƒì„±. (level rv ë²„ì „)

    - rv_s_t : ìµœê·¼ Sê°œ 5ë¶„ë´‰ rvì˜ í‰ê· 
    - rv_m_t : ìµœê·¼ Mê°œ 5ë¶„ë´‰ rvì˜ í‰ê· 
    - rv_l_t : ìµœê·¼ Lê°œ 5ë¶„ë´‰ rvì˜ í‰ê· 
    - rv_future_t : rv_{t+H}
    """
    df = prepare_base_rv_df(df, price_col=cfg.price_col)

    # HAR ìœˆë„ìš° í”¼ì²˜ (short / medium / long)
    df["rv_s"] = df["rv"].rolling(cfg.S).mean()
    df["rv_m"] = df["rv"].rolling(cfg.M).mean()
    df["rv_l"] = df["rv"].rolling(cfg.L).mean()

    # H-step ahead íƒ€ê²Ÿ
    df["rv_future"] = df["rv"].shift(-cfg.H)

    # ê²°ì¸¡ ì œê±°
    df = df.dropna(subset=["rv_s", "rv_m", "rv_l", "rv_future"]).copy()

    return df


def prepare_har_matrix(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
    """
    Level HAR-RV OLSìš© X, y ìƒì„±.

    X = [1, rv_s, rv_m, rv_l]
    y = rv_future
    """
    X = df[["rv_s", "rv_m", "rv_l"]]
    X = sm.add_constant(X)
    y = df["rv_future"]
    return X, y


def fit_har_ols(
    X: pd.DataFrame,
    y: pd.Series,
) -> sm.regression.linear_model.RegressionResultsWrapper:
    """Level HAR-RV OLS í”¼íŒ…."""
    model = sm.OLS(y, X, missing="drop")
    res = model.fit()
    return res


# ---------------------------------------------------------------------
# (2) log-HAR-RV
# ---------------------------------------------------------------------
def add_log_har_features(
    df: pd.DataFrame,
    cfg: HARConfig,
    eps: float = 1e-12,
) -> pd.DataFrame:
    """
    log-HAR-RVìš© S/M/L ìœˆë„ìš° í”¼ì²˜ + log-RV íƒ€ê²Ÿ ìƒì„±.

    - log_rv = log(rv + eps)
    - log_rv_s: ìµœê·¼ Sê°œ log_rv í‰ê· 
    - log_rv_m: ìµœê·¼ Mê°œ log_rv í‰ê· 
    - log_rv_l: ìµœê·¼ Lê°œ log_rv í‰ê· 
    - log_rv_future: log_rv_{t+H}
    """
    df = prepare_base_rv_df(df, price_col=cfg.price_col, eps=eps)

    df["log_rv_s"] = df["log_rv"].rolling(cfg.S).mean()
    df["log_rv_m"] = df["log_rv"].rolling(cfg.M).mean()
    df["log_rv_l"] = df["log_rv"].rolling(cfg.L).mean()

    df["log_rv_future"] = df["log_rv"].shift(-cfg.H)

    df = df.dropna(
        subset=["log_rv_s", "log_rv_m", "log_rv_l", "log_rv_future"]
    ).copy()

    return df


def prepare_log_har_matrix(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
    """
    log-HAR-RV OLSìš© X, y ìƒì„±.

    X = [1, log_rv_s, log_rv_m, log_rv_l]
    y = log_rv_future
    """
    X = df[["log_rv_s", "log_rv_m", "log_rv_l"]]
    X = sm.add_constant(X)
    y = df["log_rv_future"]
    return X, y


def fit_log_har_ols(
    X: pd.DataFrame,
    y: pd.Series,
) -> sm.regression.linear_model.RegressionResultsWrapper:
    """log-HAR-RV OLS í”¼íŒ…."""
    model = sm.OLS(y, X, missing="drop")
    res = model.fit()
    return res


def fit_log_har_for_horizons(
    df_raw: pd.DataFrame,
    horizons: Iterable[int] = (1, 3, 6, 12),
    S: int = 12,
    M: int = 48,
    L: int = 288,
    price_col: str = "Close",
    eps: float = 1e-12,
    train_ratio: float = 0.8,
) -> Dict[int, dict]:
    """
    ì—¬ëŸ¬ H(1,3,6,12 ë“±)ì— ëŒ€í•´ log-HARì„ í•œ ë²ˆì— í”¼íŒ…í•˜ê³ 
    ê²°ê³¼ë¥¼ dictë¡œ ë°˜í™˜.

    ë°˜í™˜ êµ¬ì¡° (ì˜ˆ: results[1]):
        {
            "cfg": HARConfig(...),
            "df_har": df_har,                 # log-HAR í”¼ì²˜ í¬í•¨ df
            "X_train": X_train,
            "y_train": y_train,
            "X_test": X_test,
            "y_test": y_test,
            "model": res,                     # statsmodels ê²°ê³¼ ê°ì²´
            "split_idx": split_idx,           # train/test ê²½ê³„ ì¸ë±ìŠ¤
            "y_pred_test_log": y_pred_log,    # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡
            "y_pred_test_level": y_pred_lvl,  # level (exp) ì˜ˆì¸¡
            "metrics": {
                "R2_train": ...,
                "R2_adj_train": ...,
                "MSE_test_log": ...,
                "MAE_test_log": ...,
                "MSE_test_level": ...,
                "MAE_test_level": ...,
            },
        }
    """
    # ê³µí†µ ë² ì´ìŠ¤ (rv, log_rv ë¯¸ë¦¬ ë§Œë“¤ì–´ë‘”ë‹¤)
    base_df = prepare_base_rv_df(df_raw, price_col=price_col, eps=eps)

    results: Dict[int, dict] = {}

    for H in horizons:
        cfg = HARConfig(H=H, S=S, M=M, L=L, price_col=price_col)

        df_har = add_log_har_features(base_df, cfg, eps=eps)
        X, y = prepare_log_har_matrix(df_har)

        n = len(df_har)
        split_idx = int(n * train_ratio)

        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

        res = fit_log_har_ols(X_train, y_train)

        # ì˜ˆì¸¡ (log ìŠ¤ì¼€ì¼)
        y_pred_log = res.predict(X_test)

        # level ìŠ¤ì¼€ì¼ (ì‹¤ì œ RV ìœ ì‚¬í•œ ìŠ¤ì¼€ì¼)
        y_test_lvl = np.exp(y_test)
        y_pred_lvl = np.exp(y_pred_log)

        # ê°„ë‹¨ ë©”íŠ¸ë¦­
        mse_test_log = float(((y_test - y_pred_log) ** 2).mean())
        mae_test_log = float((y_test - y_pred_log).abs().mean())

        mse_test_lvl = float(((y_test_lvl - y_pred_lvl) ** 2).mean())
        mae_test_lvl = float((y_test_lvl - y_pred_lvl).abs().mean())

        results[H] = {
            "cfg": cfg,
            "df_har": df_har,
            "X_train": X_train,
            "y_train": y_train,
            "X_test": X_test,
            "y_test": y_test,
            "model": res,
            "split_idx": split_idx,
            "y_pred_test_log": y_pred_log,
            "y_pred_test_level": y_pred_lvl,
            "metrics": {
                "R2_train": float(res.rsquared),
                "R2_adj_train": float(res.rsquared_adj),
                "MSE_test_log": mse_test_log,
                "MAE_test_log": mae_test_log,
                "MSE_test_level": mse_test_lvl,
                "MAE_test_level": mae_test_lvl,
            },
        }

    return results

def grid_search_log_har_sml(
    df_raw: pd.DataFrame,
    H: int = 1,
    S_candidates: Iterable[int] = (6, 12, 18, 24),            # 0.5h, 1h, 1.5h, 2h
    M_candidates: Iterable[int] = (24, 48, 72, 96),           # 2h, 4h, 6h, 8h
    L_candidates: Iterable[int] = (144, 288, 432, 576),       # 12h, 24h, 36h, 48h
    price_col: str = "Close",
    eps: float = 1e-12,
    train_ratio: float = 0.8,
    metric: str = "MAE_test_level",   # ìµœì í™” ê¸°ì¤€
    minimize: bool = True,            # Trueë©´ metric ìµœì†Œí™”, Falseë©´ ìµœëŒ€í™”
) -> Dict[str, object]:
    """
    Hë¥¼ ê³ ì •í•˜ê³  S, M, L í›„ë³´ë¥¼ ìë™ìœ¼ë¡œ íƒìƒ‰í•˜ëŠ” ê·¸ë¦¬ë“œ ì„œì¹˜.

    ì˜ˆ)
        search_res = grid_search_log_har_sml(df_raw, H=1)
        best_key = search_res["best_key"]          # (S,M,L) íŠœí”Œ
        best_summary = search_res["summary_df"].head()

    ë°˜í™˜:
        {
            "summary_df":  ê° (S,M,L)ë³„ ì„±ëŠ¥ ìš”ì•½ DataFrame (MultiIndex),
            "best_key":    (S_best, M_best, L_best),
            "best_result": best_result_dict (fit_log_har_for_horizonsì—ì„œ ì“°ë˜ êµ¬ì¡°ì™€ ê±°ì˜ ë™ì¼),
            "all_results": {(S,M,L): result_dict, ...},
            "metric":      metric ì´ë¦„,
        }
    """
    # ê³µí†µ ë² ì´ìŠ¤ (rv, log_rv ë¯¸ë¦¬ ìƒì„±)
    base_df = prepare_base_rv_df(df_raw, price_col=price_col, eps=eps)

    all_results: Dict[tuple, dict] = {}
    summary_rows = []

    for S in S_candidates:
        for M in M_candidates:
            if M < S:
                continue  # ì¤‘ê¸° ìœˆë„ìš°ëŠ” ë‹¨ê¸°ë³´ë‹¤ ê¸¸ì–´ì•¼ í•¨
            for L in L_candidates:
                if L < M:
                    continue  # ì¥ê¸° ìœˆë„ìš°ëŠ” ì¤‘ê¸°ë³´ë‹¤ ê¸¸ì–´ì•¼ í•¨

                cfg = HARConfig(H=H, S=S, M=M, L=L, price_col=price_col)

                # log-HAR í”¼ì²˜ ìƒì„±
                df_har = add_log_har_features(base_df, cfg, eps=eps)

                # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
                if len(df_har) < 500:  # í•„ìš”í•˜ë©´ ì¡°ì •
                    continue

                X, y = prepare_log_har_matrix(df_har)

                n = len(df_har)
                split_idx = int(n * train_ratio)

                X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
                y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]

                res = fit_log_har_ols(X_train, y_train)

                # ì˜ˆì¸¡ (log ìŠ¤ì¼€ì¼)
                y_pred_log = res.predict(X_test)

                # level ìŠ¤ì¼€ì¼ (ì‹¤ì œ RV ìŠ¤ì¼€ì¼)
                y_test_lvl = np.exp(y_test)
                y_pred_lvl = np.exp(y_pred_log)

                mse_test_log = float(((y_test - y_pred_log) ** 2).mean())
                mae_test_log = float((y_test - y_pred_log).abs().mean())

                mse_test_lvl = float(((y_test_lvl - y_pred_lvl) ** 2).mean())
                mae_test_lvl = float((y_test_lvl - y_pred_lvl).abs().mean())

                key = (S, M, L)

                metrics_dict = {
                    "R2_train": float(res.rsquared),
                    "R2_adj_train": float(res.rsquared_adj),
                    "MSE_test_log": mse_test_log,
                    "MAE_test_log": mae_test_log,
                    "MSE_test_level": mse_test_lvl,
                    "MAE_test_level": mae_test_lvl,
                }

                all_results[key] = {
                    "cfg": cfg,
                    "df_har": df_har,
                    "X_train": X_train,
                    "y_train": y_train,
                    "X_test": X_test,
                    "y_test": y_test,
                    "model": res,
                    "split_idx": split_idx,
                    "y_pred_test_log": y_pred_log,
                    "y_pred_test_level": y_pred_lvl,
                    "metrics": metrics_dict,
                }

                summary_rows.append(
                    {
                        "S": S,
                        "M": M,
                        "L": L,
                        **metrics_dict,
                    }
                )

    if not summary_rows:
        raise ValueError("ìœ íš¨í•œ (S,M,L) ì¡°í•©ì—ì„œ ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    summary_df = pd.DataFrame(summary_rows)
    summary_df = summary_df.set_index(["S", "M", "L"])

    if metric not in summary_df.columns:
        raise ValueError(f"metric='{metric}' ì´(ê°€) summary_df ì»¬ëŸ¼ì— ì—†ìŠµë‹ˆë‹¤: {summary_df.columns.tolist()}")

    # ìµœì  ì¡°í•© ì„ íƒ
    if minimize:
        best_key = summary_df[metric].idxmin()
    else:
        best_key = summary_df[metric].idxmax()

    best_result = all_results[best_key]

    # metric ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ëœ summary_df
    ascending = minimize
    summary_df = summary_df.sort_values(metric, ascending=ascending)

    return {
        "summary_df": summary_df,
        "best_key": best_key,
        "best_result": best_result,
        "all_results": all_results,
        "metric": metric,
    }


# ---------------------------------------------------------------------
# ëª¨ë“ˆ ë‹¨ë… ì‹¤í–‰ ì˜ˆì‹œ (ì˜µì…˜)
# ---------------------------------------------------------------------
if __name__ == "__main__":
    ROOT = Path(__file__).resolve().parents[2]  # .../trading-project
    csv_path = ROOT / "data" / "usdjpym5_indicators_0529-1204.csv"

    df_raw = load_usdjpy_indicators(csv_path)

    # ì˜ˆì‹œ: log-HAR H={1,3,6,12}
    results = fit_log_har_for_horizons(df_raw, horizons=(1, 3, 6, 12))

    for H, r in sorted(results.items()):
        print(f"\n==== H = {H} ====")
        print("R2_train:", r["metrics"]["R2_train"])
        print("MSE_test_log:", r["metrics"]["MSE_test_log"])
